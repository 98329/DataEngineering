{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2cc3670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: get-chrome-driver in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.3.20)\n",
      "Requirement already satisfied: bs4>=0.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from get-chrome-driver) (0.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from get-chrome-driver) (2.31.0)\n",
      "Requirement already satisfied: urllib3>=1.26.12 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from get-chrome-driver) (1.26.16)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from get-chrome-driver) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from bs4>=0.0.1->get-chrome-driver) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.31.0->get-chrome-driver) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.31.0->get-chrome-driver) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.31.0->get-chrome-driver) (2023.7.22)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer>=0.9.0->get-chrome-driver) (8.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer>=0.9.0->get-chrome-driver) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer>=0.9.0->get-chrome-driver) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4>=0.0.1->get-chrome-driver) (2.4)\n",
      "Requirement already satisfied: selenium in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.18.1)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: pymysql in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install get-chrome-driver\n",
    "!pip install selenium\n",
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc228546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f48750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "### WEB scraping with selenium\n",
    "\n",
    "def browser(engine, term):\n",
    "    # Remove stopwords\n",
    "    sw = stopwords.words('english')\n",
    "    words_ns = [word for word in term.split() if word.lower() not in sw]\n",
    "\n",
    "    # Construct search URL\n",
    "    search_url = engine + \"+\".join(words_ns)\n",
    "\n",
    "    # Set up Selenium options\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  # Run Chrome in headless mode (no GUI)\n",
    "\n",
    "    # Provide path to chromedriver executable directly in webdriver.Chrome()\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    # Get search results\n",
    "    driver.get(search_url)\n",
    "    html = driver.page_source\n",
    "\n",
    "    # Parse HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    links = soup.find_all(\"a\")\n",
    "    search_results = []\n",
    "\n",
    "    # Regular expression pattern to extract URLs\n",
    "    url_pattern = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "\n",
    "    for link in links:\n",
    "        href = link.get(\"href\")\n",
    "        if href:\n",
    "            # Extract URLs using regular expression\n",
    "            match = re.search(url_pattern, href)\n",
    "            if match:\n",
    "                url = match.group(0)\n",
    "                search_results.append(url)\n",
    "\n",
    "    # Close Selenium WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b018198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pymysql\n",
    "from tkinter import Tk, Label, Button, Entry, Text\n",
    "\n",
    "\n",
    "\n",
    "def mysearch():\n",
    "    term = txt1.get()\n",
    "    engines = (\n",
    "    \"https://www.google.com/search?q=\",\n",
    "    \"https://www.bing.com/?q=\",\n",
    "    \"https://search.yahoo.com/search?p=\",\n",
    "    \"https://duckduckgo.com/?q=\",\n",
    "    \"https://news.search.yahoo.com/search?p=\"\n",
    "    )\n",
    "\n",
    "    exclude_words = [\"google\", \"yahoo\", \"microsoft\",\"duckduckgo\", \"bing\"]  # Words to exclude from search results\n",
    "\n",
    "    all_results = []  # List to collect all search results\n",
    "    for engine in engines:\n",
    "        results = browser(engine, term)\n",
    "        all_results.extend(results)  # Append results to the list\n",
    "\n",
    "    # Filter out results containing certain words\n",
    "    filtered_results = [result for result in all_results if not any(word in result.lower() for word in exclude_words)]\n",
    "\n",
    "    # Count occurrences of each URL\n",
    "    url_counts = Counter(filtered_results)\n",
    "\n",
    "    # Get URLs ordered by their count, from most repeated to least repeated\n",
    "    ordered_urls = url_counts.most_common()\n",
    "\n",
    "    # Clear previous results\n",
    "    txt2.delete('1.0', 'end')\n",
    "\n",
    "    # Insert results into the Text widget\n",
    "    for url, count in ordered_urls:\n",
    "        txt2.insert('end', f\"URL: {url}\\nCount: {count}\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "###Conecting to MySQL server --- Local host#\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Connect to MySQL server\n",
    "        myConnection = pymysql.connect(host='localhost', user='root', db='my_custom_bot')\n",
    "\n",
    "        # Create a cursor object\n",
    "        cursor = myConnection.cursor()\n",
    "\n",
    "        # SQL query with placeholder for values\n",
    "        sql = f'INSERT INTO New_Engine (Search, URL, Count) VALUES (%s, %s, %s)'\n",
    "\n",
    "        # List of tuples containing values to be inserted\n",
    "        values = [(term, url, count) for url, count in url_counts.items()]\n",
    "\n",
    "        # Execute the SQL query with executemany() method\n",
    "        cursor.executemany(sql, values)\n",
    "\n",
    "        # Commit the changes\n",
    "        myConnection.commit()\n",
    "\n",
    "    except pymysql.Error as e:\n",
    "        # Handle any potential errors\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        myConnection.close()\n",
    "\n",
    "        \n",
    "        \n",
    "                      \n",
    "        \n",
    "## GUI ----Creating the browser window #######################################################\n",
    "\n",
    "def resize_window(window, width_percent, height_percent):\n",
    "    screen_width = window.winfo_screenwidth()\n",
    "    screen_height = window.winfo_screenheight()\n",
    "\n",
    "    width = int(screen_width * width_percent)\n",
    "    height = int(screen_height * height_percent)\n",
    "\n",
    "    x = (screen_width - width) // 2\n",
    "    y = (screen_height - height) // 2\n",
    "\n",
    "    window.geometry(f\"{width}x{height}+{x}+{y}\")\n",
    "\n",
    "window = Tk()\n",
    "window.title(\"Browser project DS1E400\")\n",
    "\n",
    "# Resize the window to 80% width and 70% height of the screen\n",
    "resize_window(window, 0.8, 0.7)\n",
    "\n",
    "lbl = Label(window, text=\"the medical device development process for today\")\n",
    "lbl.place(relx=0.05, rely=0.02, relwidth=0.9, relheight=0.05)\n",
    "\n",
    "txt1 = Entry(window, bg='white')\n",
    "txt1.place(relx=0.05, rely=0.1, relwidth=0.4, relheight=0.05)\n",
    "\n",
    "txt2 = Text(window, bg='white')\n",
    "txt2.place(relx=0.05, rely=0.18, relwidth=0.9, relheight=0.6)\n",
    "\n",
    "btn = Button(window, text=\"New Search\", command=mysearch)\n",
    "btn[\"fg\"] = \"white\"\n",
    "btn[\"bg\"] = \"blue\"\n",
    "btn.place(relx=0.55, rely=0.1, relwidth=0.2, relheight=0.05)\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa6bc28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
